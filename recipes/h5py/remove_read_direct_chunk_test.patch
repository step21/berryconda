diff --git a/h5py/tests/test_h5d_direct_chunk.py b/h5py/tests/test_h5d_direct_chunk.py
index c448129..4cc9ab9 100644
--- a/h5py/tests/test_h5d_direct_chunk.py
+++ b/h5py/tests/test_h5d_direct_chunk.py
@@ -61,58 +61,3 @@ class TestReadDirectChunk(TestCase):
             self.assertEqual(compressed_frame, data)
             # No filter must be disabled
             self.assertEqual(filter_mask, 0)
-
-    def test_read_uncompressed_offsets(self):
-
-        filename = self.mktemp().encode()
-        frame = numpy.arange(16).reshape(4, 4)
-        with h5py.File(filename, "w") as filehandle:
-            dataset = filehandle.create_dataset("frame",
-                                                maxshape=(1,) + frame.shape,
-                                                shape=(1,) + frame.shape,
-                                                compression="gzip",
-                                                compression_opts=9)
-            # Write uncompressed data
-            DISABLE_ALL_FILTERS = 0xFFFFFFFF
-            dataset.id.write_direct_chunk((0, 0, 0), frame.tostring(), filter_mask=DISABLE_ALL_FILTERS)
-
-        # FIXME: Here we have to close the file and load it back else
-        #     a runtime error occurs:
-        #     RuntimeError: Can't get storage size of chunk (chunk storage is not allocated)
-        with h5py.File(filename, "r") as filehandle:
-            dataset = filehandle["frame"]
-            filter_mask, compressed_frame = dataset.id.read_direct_chunk((0, 0, 0))
-
-        # At least 1 filter is supposed to be disabled
-        self.assertNotEqual(filter_mask, 0)
-        self.assertEqual(compressed_frame, frame.tostring())
-
-    def test_read_write_chunk(self):
-
-        filename = self.mktemp().encode()
-        filehandle = h5py.File(filename, "w")
-
-        # create a reference
-        frame = numpy.arange(16).reshape(4, 4)
-        frame_dataset = filehandle.create_dataset("source",
-                                                  data=frame,
-                                                  compression="gzip",
-                                                  compression_opts=9)
-        # configure an empty dataset
-        filter_mask, compressed_frame = frame_dataset.id.read_direct_chunk((0, 0))
-        dataset = filehandle.create_dataset("created",
-                                            shape=frame_dataset.shape,
-                                            maxshape=frame_dataset.shape,
-                                            chunks=frame_dataset.chunks,
-                                            dtype=frame_dataset.dtype,
-                                            compression="gzip",
-                                            compression_opts=9)
-
-        # copy the data
-        dataset.id.write_direct_chunk((0, 0), compressed_frame, filter_mask=filter_mask)
-        filehandle.close()
-
-        # checking
-        filehandle = h5py.File(filename, "r")
-        dataset = filehandle["created"][...]
-        numpy.testing.assert_array_equal(dataset, frame)
